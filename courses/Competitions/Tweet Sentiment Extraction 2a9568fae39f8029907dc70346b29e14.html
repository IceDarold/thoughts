<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Tweet Sentiment Extraction</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 10px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.callout img.notion-static-icon {
	width: 1em;
	height: 1em;
}

.callout p {
	margin: 0;
}

.callout h1,
.callout h2,
.callout h3 {
	margin: 0 0 0.6rem;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.highlight-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.highlight-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.highlight-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.highlight-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.highlight-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.highlight-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(42, 28, 0, 0.07);
}
.highlight-brown_background {
	background: rgba(139, 46, 0, 0.086);
}
.highlight-orange_background {
	background: rgba(224, 101, 1, 0.129);
}
.highlight-yellow_background {
	background: rgba(211, 168, 0, 0.137);
}
.highlight-teal_background {
	background: rgba(0, 100, 45, 0.09);
}
.highlight-blue_background {
	background: rgba(0, 124, 215, 0.094);
}
.highlight-purple_background {
	background: rgba(102, 0, 178, 0.078);
}
.highlight-pink_background {
	background: rgba(197, 0, 93, 0.086);
}
.highlight-red_background {
	background: rgba(223, 22, 0, 0.094);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.block-color-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.block-color-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.block-color-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.block-color-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.block-color-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.block-color-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(229, 242, 252, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 118, 217, 0.203); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="2a9568fa-e39f-8029-907d-c70346b29e14" class="page sans"><header><h1 class="page-title">Tweet Sentiment Extraction</h1><p class="page-description"></p></header><div class="page-body"><h1 id="2a9568fa-e39f-8047-a62d-eb35fdc9c1ef" class="">Карта задачи (что именно оптимизируем)</h1><ul id="2a9568fa-e39f-80ba-8b24-d1f5aee8fbc1" class="bulleted-list"><li style="list-style-type:disc"><strong>Цель:</strong> извлечь подстроку твита (support phrase) по метке <em>sentiment</em> ∈ {positive, negative, neutral}.</li></ul><ul id="2a9568fa-e39f-80d3-8178-fd807a2f434b" class="bulleted-list"><li style="list-style-type:disc"><strong>Метрика:</strong> средний <strong>Jaccard</strong> между предсказанной и истинной подстрокой по символам/словам.</li></ul><ul id="2a9568fa-e39f-8083-8d1e-f2f02e9bb314" class="bulleted-list"><li style="list-style-type:disc"><strong>Подводные камни:</strong> короткие тексты, пунктуация, эмодзи, повторы символов, пробелы/апострофы, нейтральные твиты (часто «весь текст»), несоответствие токенов и символов (offset mapping).</li></ul><p id="2a9568fa-e39f-80fb-9d90-ca2ea431233b" class="">Полезные разборы прямо по этому конкурсу:</p><ul id="2a9568fa-e39f-8025-a68a-d69b25dfd23f" class="bulleted-list"><li style="list-style-type:disc">Команда <strong>Dark of the Moon</strong> (1-е место): трансформеры (start/end), офсеты символов, 2-й уровень на символах, переранкинг кандидатов. Короткий обзор + код. (<a href="https://www.kaggle.com/competitions/tweet-sentiment-extraction/writeups/dark-of-the-moon-quick-1st-place-solution-overview?utm_source=chatgpt.com">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-8062-a820-c1ccd97724b6" class="bulleted-list"><li style="list-style-type:disc">Обсуждения с деталями по ансамблям RoBERTa/XLNet/ALBERT и постпроцессингу. (<a href="https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159910">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-806e-94c4-fec0d12520ee" class="bulleted-list"><li style="list-style-type:disc">Непосредственная страница соревнования. (<a href="https://www.kaggle.com/competitions/tweet-sentiment-extraction">Kaggle</a>)</li></ul><p id="2a9568fa-e39f-805a-9d7a-d0cc832e1c9a" class="">Сильные идеи из похожих спан-задач:</p><ul id="2a9568fa-e39f-8031-a16c-eef738612b8c" class="bulleted-list"><li style="list-style-type:disc"><strong>NBME (медицинские спаны)</strong> — победные решения с DeBERTa-v3-large, multi-sample dropout, AWP/FGM, офсеты и аккуратный постпроцесс. Это отлично переносится на извлечение фраз. (<a href="https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/323095">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-801f-b7b5-d5113b69a4cf" class="bulleted-list"><li style="list-style-type:disc"><strong>Coleridge (наименования датасетов, тоже спаны + поиск):</strong> метрик-лернинг, переранкинг и гибрид правил+LM. Полезен сам принцип генерации кандидатов и их переоценки. (<a href="https://www.kaggle.com/competitions/coleridgeinitiative-show-us-the-data/writeups/zalo-ftw-1st-place-solution-metric-learning-and-gp?utm_source=chatgpt.com">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-8029-969c-d6bc7c84fa40" class="bulleted-list"><li style="list-style-type:disc"><strong>BERTweet</strong> — твиттер-доменная предтренировка часто обгоняет общий RoBERTa на твиттер-задачах. (<a href="https://arxiv.org/abs/2005.10200?utm_source=chatgpt.com">arXiv</a>)</li></ul><hr id="2a9568fa-e39f-8067-8e4f-f7e7fa5ed002"/><h1 id="2a9568fa-e39f-8078-b55c-cc3327992919" class="">Рецепт «до топ-1»</h1><h2 id="2a9568fa-e39f-80d7-8e05-e04889d1c40e" class="">0) Валидация и подготовка</h2><ul id="2a9568fa-e39f-8004-bbac-d87d290dd3b7" class="bulleted-list"><li style="list-style-type:disc"><strong>CV:</strong> стратиф. 5-fold по <em>sentiment</em>. Сохраняем mapping «char⇄token».</li></ul><ul id="2a9568fa-e39f-8034-9916-d9770f617630" class="bulleted-list"><li style="list-style-type:disc"><strong>Метки:</strong> для каждой строки строим таргеты start/end по <strong>char-offset → токены</strong>, + бинарная маска символов для 2-го уровня.</li></ul><ul id="2a9568fa-e39f-8051-969d-cf86ac31980e" class="bulleted-list"><li style="list-style-type:disc"><strong>Чистка (минимальная):</strong> нормализация пробелов, унификация апострофов, <strong>никакого lowercasing</strong>; эмодзи оставляем, они информативны.</li></ul><h2 id="2a9568fa-e39f-806b-b257-e06300a87235" class="">1) Моно-модели (уровень 1, токены: start/end)</h2><p id="2a9568fa-e39f-80a8-85bf-ec2da839d2bf" class="">Три семейства — разная «оптика» на текст, позже смешаем:</p><ol type="1" id="2a9568fa-e39f-80c5-b8ca-df485423815c" class="numbered-list" start="1"><li><strong>DeBERTa-v3-large</strong> (baseline-SOTA для спанов). LLRD, warmup cosine, <strong>multi-sample dropout</strong>, <strong>AWP</strong> после стабилизации, label smoothing 0.05. Макс-длина 128–192. (<a href="https://arxiv.org/abs/2111.09543?utm_source=chatgpt.com">arXiv</a>)</li></ol><ol type="1" id="2a9568fa-e39f-80e8-acaf-d4abca4c25e2" class="numbered-list" start="2"><li><strong>RoBERTa-large</strong> (классика этого конкурса), head «двойной логит» на start/end, + optional QA-формулировка («question=sentiment, context=tweet»). (<a href="https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159910">Kaggle</a>)</li></ol><ol type="1" id="2a9568fa-e39f-8003-8383-ef59670000c3" class="numbered-list" start="3"><li><strong>BERTweet-large</strong> (доменно-специфичный буст). Можно сделать <strong>доп. MLM-адаптацию</strong> на корпусе train+test (unsup) перед fine-tune. (<a href="https://arxiv.org/pdf/2005.10200?utm_source=chatgpt.com">arXiv</a>)</li></ol><p id="2a9568fa-e39f-809b-a31b-ff4105cb1513" class="">Обучение: 5 фолдов × 2–3 сида на модель (итого ~30 чекпоинтов). Трюки из NBME переносятся как есть: AWP/FGM, gradient checkpointing, fp16/8-bit оптимизатор, аккуратная работа с офсетами. (<a href="https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/323095">Kaggle</a>)</p><h2 id="2a9568fa-e39f-8078-8944-d3fe9bc12826" class="">2) Постпроцесс токен-&gt;символ (правила, которые реально дают очки)</h2><ul id="2a9568fa-e39f-80bc-a6dd-f7e84e494a1b" class="bulleted-list"><li style="list-style-type:disc">Сглаживание логитов <strong>1D-conv/TA smoothing</strong> по последовательности.</li></ul><ul id="2a9568fa-e39f-805c-862d-e3ac56a7a1cd" class="bulleted-list"><li style="list-style-type:disc">Исправление «start&gt;end»: берём ближайший допустимый интервал.</li></ul><ul id="2a9568fa-e39f-80e4-b42a-c63307fbade3" class="bulleted-list"><li style="list-style-type:disc"><strong>Расширение к ближ. границам слов/эмодзи</strong> (не рвём юникод).</li></ul><ul id="2a9568fa-e39f-8058-b11e-db759dde4b42" class="bulleted-list"><li style="list-style-type:disc"><strong>Heuristic for neutral:</strong> если <em>neutral</em> и доверие ниже τ — <strong>возвращаем весь твит</strong> (этот хак часто спасает LB). (<a href="https://www.kaggle.com/competitions/tweet-sentiment-extraction/writeups/dark-of-the-moon-quick-1st-place-solution-overview?utm_source=chatgpt.com">Kaggle</a>)</li></ul><h2 id="2a9568fa-e39f-8041-bc09-c8b2cf61fea5" class="">3) Генерация кандидатов + переранкинг (уровень 2, символы)</h2><ul id="2a9568fa-e39f-8059-bec8-ddd727c861dd" class="bulleted-list"><li style="list-style-type:disc">Из каждого уровня-1 берём <strong>top-k</strong> (k≈5–8) спанов по сумме логитов/длини с пенальти.</li></ul><ul id="2a9568fa-e39f-80b4-abd6-f31c0f8eb516" class="bulleted-list"><li style="list-style-type:disc">Собираем <strong>пул кандидатов</strong> (объединение по моделям/сидам) и <strong>учим реранкер</strong>:<ul id="2a9568fa-e39f-800b-837d-fab86a620ec2" class="bulleted-list"><li style="list-style-type:circle">Вариант A: <strong>символьная CNN/GRU-голова</strong> на вырезке + контекст твита (+ метка sentiment) → регрессия Jaccard (учим на train, где Jaccard известен).</li></ul><ul id="2a9568fa-e39f-80ac-993b-dec6fec64d41" class="bulleted-list"><li style="list-style-type:circle">Вариант B: лёгкий <strong>RoBERTa-base</strong> «pair scoring»: [sentiment as prompt] + [candidate span highlighted] → регрессия.</li></ul><ul id="2a9568fa-e39f-8007-a590-c29605bac7d5" class="bulleted-list"><li style="list-style-type:circle">Такой трюк использовался в TSE-решениях: предсказывать «правильность» кандидата и выбирать лучшее. (<a href="https://tangliyan.com/blog/posts/kaggle_tweet_sent2/?utm_source=chatgpt.com">tangliyan.com</a>)</li></ul></li></ul><ul id="2a9568fa-e39f-804b-9929-dcc11421196d" class="bulleted-list"><li style="list-style-type:disc">Итоговый выбор = кандидат с макс. score реранкера.</li></ul><ul id="2a9568fa-e39f-8065-9d04-dc4cbf0fba25" class="bulleted-list"><li style="list-style-type:disc">(У Dark of the Moon был <strong>символьный второй уровень</strong> и стэкинг — идея та же.) (<a href="https://www.kaggle.com/competitions/tweet-sentiment-extraction/writeups/dark-of-the-moon-quick-1st-place-solution-overview?utm_source=chatgpt.com">Kaggle</a>)</li></ul><h2 id="2a9568fa-e39f-80a3-9f29-fc5d434fd822" class="">4) Ансамбль</h2><ul id="2a9568fa-e39f-8090-b52f-e18386384417" class="bulleted-list"><li style="list-style-type:disc"><strong>На уровне логитов:</strong> усредняем start/end логиты внутри семейства (фолд×сид), затем <strong>смешиваем семейства</strong> с весами из OOF (DeBERTa &gt; RoBERTa &gt; BERTweet).</li></ul><ul id="2a9568fa-e39f-80e8-825a-c4e2ec196e77" class="bulleted-list"><li style="list-style-type:disc"><strong>На уровне кандидатов:</strong> после постпроцесса объединяем top-k и отдаём в единый реранкер (часто сильнее простого бленда).</li></ul><ul id="2a9568fa-e39f-801d-953c-ea952a3c0bcb" class="bulleted-list"><li style="list-style-type:disc">В NBME/Coleridge ансамбли + сильный постпроцесс были критичны. (<a href="https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/323095">Kaggle</a>)</li></ul><h2 id="2a9568fa-e39f-8018-815c-de3ab73531d7" class="">5) Псевдо-разметка (semi-supervised)</h2><ul id="2a9568fa-e39f-80e1-800d-d4dd49e4844c" class="bulleted-list"><li style="list-style-type:disc">Прогоняем сильный ансамбль по <strong>test</strong> → берём <strong>high-confidence</strong> спаны (gap между top-1/2 start и end-логитами, длина в разумных пределах).</li></ul><ul id="2a9568fa-e39f-8076-8f65-e2d56e6f51e9" class="bulleted-list"><li style="list-style-type:disc">Сливаем с train, <strong>re-fine-tune</strong> DeBERTa/roberta одной эпохой (низкий LR). Эта схема отлично работала в NBME. (<a href="https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/323095">Kaggle</a>)</li></ul><h2 id="2a9568fa-e39f-809c-a2b6-cc5790f4a169" class="">6) Мультитаск-регуляризация</h2><ul id="2a9568fa-e39f-8013-b3bb-de8f13fd997a" class="bulleted-list"><li style="list-style-type:disc">Параллельно головам start/end добавляем <strong>классификацию sentiment</strong> (восстановление входной метки). Это стабилизирует представления и даёт ~+0.2–0.4 Jaccard OOF на похожих задачах.</li></ul><h2 id="2a9568fa-e39f-80b2-ac98-e57408ef6576" class="">7) Специально для твитов</h2><ul id="2a9568fa-e39f-8015-8f36-f3e01e993c45" class="bulleted-list"><li style="list-style-type:disc">Внедряем <strong>BERTweet</strong> как одно из семейств + лёгкий <strong>domain MLM</strong> на корпусе конкурcа — подтверждённый буст на твиттер-данных. (<a href="https://arxiv.org/pdf/2005.10200?utm_source=chatgpt.com">arXiv</a>)</li></ul><ul id="2a9568fa-e39f-8099-b0a8-f5a488ab5f9b" class="bulleted-list"><li style="list-style-type:disc">Добавляем признак <strong>«эмодзи-маска»</strong> (binary channel) в символьный 2-й уровень: эмодзи часто несут тон.</li></ul><ul id="2a9568fa-e39f-807f-bff2-c523f785b7a2" class="bulleted-list"><li style="list-style-type:disc">Лёгкий <strong>словари/правила</strong> fallback: если модель «сомневается», ищем ближайший кластер позитивных/негативных слов (только как запасной вариант).</li></ul><h2 id="2a9568fa-e39f-80de-a66e-c9e25f2dfa02" class="">8) Гиперпараметры (проверено в спан-задачах)</h2><ul id="2a9568fa-e39f-8059-8bb9-f57b62687f1e" class="bulleted-list"><li style="list-style-type:disc">LLRD (lr head 1e-3, top-layers 5e-5 → нижние 1e-5), <strong>warmup 10%</strong>, cosine/linear decay, batch 8–16 с grad-accum.</li></ul><ul id="2a9568fa-e39f-8086-8445-c48bd1ca1511" class="bulleted-list"><li style="list-style-type:disc"><strong>AWP</strong> (eps ~0.01, start epoch 2), <strong>weight decay 0.01</strong>, <strong>dropout 0.2–0.5</strong> (multi-sample).</li></ul><ul id="2a9568fa-e39f-808f-ac7f-cae22c5cb31f" class="bulleted-list"><li style="list-style-type:disc">Max length 160 (эмпирически хватает для большинства твитов).</li></ul><ul id="2a9568fa-e39f-8020-818e-f3c77ad8a6ca" class="bulleted-list"><li style="list-style-type:disc">Mixed precision, gradient checkpointing.</li></ul><hr id="2a9568fa-e39f-80e9-8e39-c0e38c07051d"/><h1 id="2a9568fa-e39f-8017-9154-f793b96e8dfb" class="">Что мы «берём» у победителей (и где это описано)</h1><ul id="2a9568fa-e39f-806f-8e48-e3ffdcebfaa4" class="bulleted-list"><li style="list-style-type:disc"><strong>Двухуровневая архитектура (токены → символы) + переранкинг</strong> — концепт из 1-го места TSE (Dark of the Moon). (<a href="https://www.kaggle.com/competitions/tweet-sentiment-extraction/writeups/dark-of-the-moon-quick-1st-place-solution-overview?utm_source=chatgpt.com">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-80b2-ab30-d8b54424e2ed" class="bulleted-list"><li style="list-style-type:disc"><strong>Жёсткий постпроцесс спанов, AWP/FGM, multi-sample dropout, LLRD, ансамбли</strong> — best practice из <strong>NBME</strong> победных разборов. (<a href="https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/323095">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-8067-854c-d6271ca27597" class="bulleted-list"><li style="list-style-type:disc"><strong>Кандидаты + реранкинг/метрик-лернинг</strong> — из <strong>Coleridge</strong> 1-го места. (<a href="https://www.kaggle.com/competitions/coleridgeinitiative-show-us-the-data/writeups/zalo-ftw-1st-place-solution-metric-learning-and-gp?utm_source=chatgpt.com">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-80f2-b1b3-fc9c212af871" class="bulleted-list"><li style="list-style-type:disc"><strong>Доменно-специфичная предобучалка для твитов</strong> — <strong>BERTweet</strong>. (<a href="https://arxiv.org/pdf/2005.10200?utm_source=chatgpt.com">arXiv</a>)</li></ul><hr id="2a9568fa-e39f-80f5-83ef-c2060414c111"/><h1 id="2a9568fa-e39f-800b-b07e-e6ab3ce12439" class="">Мини-план запуска (что делать по шагам)</h1><ol type="1" id="2a9568fa-e39f-80f3-963f-dda66fee4b8a" class="numbered-list" start="1"><li>Собрать датасет с корректными <strong>char↔token offsets</strong> и надёжной OOF-оценкой (5-fold).</li></ol><ol type="1" id="2a9568fa-e39f-80bb-99db-c8a9d59cfe73" class="numbered-list" start="2"><li>Обучить <strong>DeBERTa-v3-large</strong> (5×2) + <strong>RoBERTa-large</strong> (5×2) + <strong>BERTweet-large</strong> (5×1). (<a href="https://arxiv.org/abs/2111.09543?utm_source=chatgpt.com">arXiv</a>)</li></ol><ol type="1" id="2a9568fa-e39f-80d1-b6bb-fa8987bdb0fd" class="numbered-list" start="3"><li>Постпроцесс логитов → k кандидатов на твит (правила из п.2).</li></ol><ol type="1" id="2a9568fa-e39f-8031-a7e7-c9f39d14941e" class="numbered-list" start="4"><li>Обучить <strong>реранкер</strong> на трене (регрессия Jaccard по кандидатам). (<a href="https://tangliyan.com/blog/posts/kaggle_tweet_sent2/?utm_source=chatgpt.com">tangliyan.com</a>)</li></ol><ol type="1" id="2a9568fa-e39f-8067-b754-f70cd1f64e23" class="numbered-list" start="5"><li>Ансамбль логитов (внутри семейства) → общий пул кандидатов → <strong>единый реранкер</strong>.</li></ol><ol type="1" id="2a9568fa-e39f-8088-8a1c-faa06e3f5502" class="numbered-list" start="6"><li>Сделать <strong>псевдо-разметку</strong> по тесту, дозатюнить 1–2 эпохи. (<a href="https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/323095">Kaggle</a>)</li></ol><ol type="1" id="2a9568fa-e39f-805d-81a2-c5a48f1af245" class="numbered-list" start="7"><li>Финальный инференс: TTA по длине/границам + реранкинг → сабмит.</li></ol><hr id="2a9568fa-e39f-800f-b3ac-ec57225d8ea4"/><h1 id="2a9568fa-e39f-80f9-8c39-e8bf4249adca" class="">Ссылки, чтобы «копировать приёмы»</h1><ul id="2a9568fa-e39f-80b7-8a1e-df46f3a1ef87" class="bulleted-list"><li style="list-style-type:disc"><strong>TSE 1-е место</strong>: обзор/ноуты/код. (<a href="https://www.kaggle.com/competitions/tweet-sentiment-extraction/writeups/dark-of-the-moon-quick-1st-place-solution-overview?utm_source=chatgpt.com">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-807d-a064-ecd543114d98" class="bulleted-list"><li style="list-style-type:disc">Обсуждения TSE с идеями по RoBERTa/XLNet/ALBERT, постпроцессу. (<a href="https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159910">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-8002-9496-da1ea4c892a3" class="bulleted-list"><li style="list-style-type:disc"><strong>NBME 1-е место</strong> (DeBERTa-v3-large, офсеты, AWP/MSD): применять один в один. (<a href="https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/323095">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-8048-a564-c78fd66d4b00" class="bulleted-list"><li style="list-style-type:disc"><strong>Coleridge 1-е место</strong> (метрик-лернинг + GPT/переранкинг кандидатов). (<a href="https://www.kaggle.com/competitions/coleridgeinitiative-show-us-the-data/writeups/zalo-ftw-1st-place-solution-metric-learning-and-gp?utm_source=chatgpt.com">Kaggle</a>)</li></ul><ul id="2a9568fa-e39f-8023-9c9d-e0a3e8722985" class="bulleted-list"><li style="list-style-type:disc"><strong>BERTweet (tweet-domain PLM)</strong> — статья/репозиторий. (<a href="https://arxiv.org/pdf/2005.10200?utm_source=chatgpt.com">arXiv</a>)</li></ul><p id="2a9568fa-e39f-8036-a2de-cf94a2402969" class="">Если хочешь, могу сразу накинуть скелет кода (HF Trainer + офсеты + генерация кандидатов и реранкер) — так быстрее собрать весь конвейер и померить OOF без «магии».</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>